{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf43d12b",
   "metadata": {},
   "source": [
    "# 🎯 Classification d'Intentions - Neural Chat Engine\n",
    "\n",
    "## Objectif\n",
    "Développer un modèle de classification d'intentions multi-domaines utilisant DistilBERT pour notre chatbot IA avancé.\n",
    "\n",
    "## Domaines couverts\n",
    "- 🔧 **Assistance technique** (documentation, debugging)\n",
    "- 🛍️ **E-commerce** (recommandations, support client)\n",
    "- 👥 **RH** (screening, questions d'emploi)\n",
    "- 🌍 **Multilingue** (traduction contextuelle)\n",
    "\n",
    "## Architecture\n",
    "- **Modèle base** : DistilBERT (distilbert-base-multilingual-cased)\n",
    "- **Classification** : Multi-labels avec confidence scoring\n",
    "- **Optimisation** : Fine-tuning avec techniques avancées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4543582",
   "metadata": {},
   "source": [
    "## 📚 Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b317bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances (si nécessaire)\n",
    "# !pip install transformers torch datasets scikit-learn matplotlib seaborn wandb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ajout du path du projet\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Imports essentiels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Transformers & ML\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Device utilisé: {device}\")\n",
    "print(f\"🔢 PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Configuration pour la reproductibilité\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Style des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251dbef6",
   "metadata": {},
   "source": [
    "## 🗂️ Chargement et Exploration des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des intentions par domaine\n",
    "INTENT_CATEGORIES = {\n",
    "    'technical': [\n",
    "        'code_debug', 'documentation_request', 'api_usage', \n",
    "        'error_explanation', 'best_practices', 'architecture_advice'\n",
    "    ],\n",
    "    'ecommerce': [\n",
    "        'product_search', 'price_inquiry', 'recommendation_request',\n",
    "        'order_status', 'return_policy', 'payment_help'\n",
    "    ],\n",
    "    'hr': [\n",
    "        'job_inquiry', 'interview_preparation', 'salary_negotiation',\n",
    "        'career_advice', 'skill_assessment', 'company_culture'\n",
    "    ],\n",
    "    'multilingual': [\n",
    "        'translation_request', 'language_learning', 'cultural_context',\n",
    "        'grammar_check', 'pronunciation_help', 'localization'\n",
    "    ],\n",
    "    'general': [\n",
    "        'greeting', 'goodbye', 'thank_you', 'apology', \n",
    "        'clarification_request', 'escalation_request'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Création du mapping des labels\n",
    "all_intents = []\n",
    "for domain, intents in INTENT_CATEGORIES.items():\n",
    "    all_intents.extend(intents)\n",
    "\n",
    "intent_to_id = {intent: i for i, intent in enumerate(all_intents)}\n",
    "id_to_intent = {i: intent for intent, i in intent_to_id.items()}\n",
    "\n",
    "print(f\"📊 Nombre total d'intentions: {len(all_intents)}\")\n",
    "print(f\"🏷️ Intentions par domaine:\")\n",
    "for domain, intents in INTENT_CATEGORIES.items():\n",
    "    print(f\"  - {domain}: {len(intents)} intentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ceb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération de données d'exemple (en attendant les vraies données)\n",
    "def generate_sample_data(num_samples_per_intent: int = 50) -> List[Dict]:\n",
    "    \"\"\"Génère des données d'exemple pour chaque intention.\"\"\"\n",
    "    \n",
    "    sample_texts = {\n",
    "        # Technical\n",
    "        'code_debug': [\n",
    "            \"Mon code Python ne fonctionne pas, pouvez-vous m'aider ?\",\n",
    "            \"J'ai une erreur dans ma fonction, comment la corriger ?\",\n",
    "            \"Help me debug this JavaScript issue\",\n",
    "            \"There's a bug in my React component\"\n",
    "        ],\n",
    "        'documentation_request': [\n",
    "            \"Où puis-je trouver la documentation de cette API ?\",\n",
    "            \"Can you show me the docs for this library?\",\n",
    "            \"I need help understanding this framework\",\n",
    "            \"Comment utiliser cette bibliothèque ?\"\n",
    "        ],\n",
    "        # E-commerce\n",
    "        'product_search': [\n",
    "            \"Je cherche un ordinateur portable pour le gaming\",\n",
    "            \"Show me smartphones under $500\",\n",
    "            \"Quels sont vos meilleurs téléphones ?\",\n",
    "            \"I'm looking for wireless headphones\"\n",
    "        ],\n",
    "        'price_inquiry': [\n",
    "            \"Quel est le prix de ce produit ?\",\n",
    "            \"How much does this cost?\",\n",
    "            \"Is there a discount available?\",\n",
    "            \"Y a-t-il des promotions en cours ?\"\n",
    "        ],\n",
    "        # HR\n",
    "        'job_inquiry': [\n",
    "            \"Quels postes sont disponibles ?\",\n",
    "            \"Are there any developer positions open?\",\n",
    "            \"I'm interested in working at your company\",\n",
    "            \"Comment postuler pour un emploi ?\"\n",
    "        ],\n",
    "        'interview_preparation': [\n",
    "            \"Comment me préparer pour l'entretien ?\",\n",
    "            \"What questions should I expect?\",\n",
    "            \"Tips for a technical interview?\",\n",
    "            \"Conseils pour réussir l'entretien\"\n",
    "        ],\n",
    "        # Multilingual\n",
    "        'translation_request': [\n",
    "            \"Pouvez-vous traduire ce texte en anglais ?\",\n",
    "            \"Translate this to French please\",\n",
    "            \"¿Puedes traducir esto al español?\",\n",
    "            \"この文を英語に翻訳してください\"\n",
    "        ],\n",
    "        # General\n",
    "        'greeting': [\n",
    "            \"Bonjour !\", \"Hello!\", \"Hi there\", \"Salut\",\n",
    "            \"Good morning\", \"Bonsoir\", \"Hey\", \"Hola\"\n",
    "        ],\n",
    "        'thank_you': [\n",
    "            \"Merci beaucoup\", \"Thank you\", \"Thanks a lot\",\n",
    "            \"Je vous remercie\", \"Much appreciated\", \"Gracias\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for intent in all_intents:\n",
    "        if intent in sample_texts:\n",
    "            base_samples = sample_texts[intent]\n",
    "        else:\n",
    "            # Génération de textes génériques pour les intentions non définies\n",
    "            base_samples = [\n",
    "                f\"This is about {intent.replace('_', ' ')}\",\n",
    "                f\"I need help with {intent.replace('_', ' ')}\",\n",
    "                f\"Question about {intent.replace('_', ' ')}\",\n",
    "                f\"How to handle {intent.replace('_', ' ')}?\"\n",
    "            ]\n",
    "        \n",
    "        # Augmentation des données\n",
    "        for i in range(num_samples_per_intent):\n",
    "            text = np.random.choice(base_samples)\n",
    "            # Ajout de variations\n",
    "            if np.random.random() > 0.7:\n",
    "                prefixes = [\"Could you help me with \", \"I have a question about \", \"\"]\n",
    "                text = np.random.choice(prefixes) + text.lower()\n",
    "            \n",
    "            data.append({\n",
    "                'text': text,\n",
    "                'intent': intent,\n",
    "                'label': intent_to_id[intent],\n",
    "                'domain': next(domain for domain, intents in INTENT_CATEGORIES.items() if intent in intents)\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Génération des données\n",
    "print(\"🔄 Génération des données d'exemple...\")\n",
    "raw_data = generate_sample_data(num_samples_per_intent=75)\n",
    "df = pd.DataFrame(raw_data)\n",
    "\n",
    "print(f\"📈 Dataset créé: {len(df)} échantillons\")\n",
    "print(f\"📊 Répartition par domaine:\")\n",
    "print(df['domain'].value_counts())\n",
    "\n",
    "# Affichage d'exemples\n",
    "print(\"\\n📝 Exemples de données:\")\n",
    "sample_data = df.groupby('domain').head(2)\n",
    "for _, row in sample_data.iterrows():\n",
    "    print(f\"  {row['domain']} | {row['intent']} | '{row['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b96f1",
   "metadata": {},
   "source": [
    "## 📊 Analyse Exploratoire des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques générales\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribution par domaine\n",
    "df['domain'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Distribution par Domaine')\n",
    "axes[0,0].set_xlabel('Domaine')\n",
    "axes[0,0].set_ylabel('Nombre d\\'échantillons')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Longueur des textes\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['text_length'].hist(bins=30, ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('Distribution de la Longueur des Textes')\n",
    "axes[0,1].set_xlabel('Longueur (caractères)')\n",
    "axes[0,1].set_ylabel('Fréquence')\n",
    "\n",
    "# Top 10 des intentions\n",
    "top_intents = df['intent'].value_counts().head(10)\n",
    "top_intents.plot(kind='barh', ax=axes[1,0], color='lightgreen')\n",
    "axes[1,0].set_title('Top 10 des Intentions')\n",
    "axes[1,0].set_xlabel('Nombre d\\'échantillons')\n",
    "\n",
    "# Nombre de mots par domaine\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "df.boxplot(column='word_count', by='domain', ax=axes[1,1])\n",
    "axes[1,1].set_title('Distribution du Nombre de Mots par Domaine')\n",
    "axes[1,1].set_xlabel('Domaine')\n",
    "axes[1,1].set_ylabel('Nombre de mots')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"📈 Statistiques descriptives:\")\n",
    "print(f\"Longueur moyenne des textes: {df['text_length'].mean():.1f} caractères\")\n",
    "print(f\"Nombre moyen de mots: {df['word_count'].mean():.1f}\")\n",
    "print(f\"Échantillons les plus courts: {df['text_length'].min()} caractères\")\n",
    "print(f\"Échantillons les plus longs: {df['text_length'].max()} caractères\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75ce57",
   "metadata": {},
   "source": [
    "## 🔧 Préparation des Données et Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ec4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du modèle\n",
    "MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "print(f\"🤖 Modèle: {MODEL_NAME}\")\n",
    "print(f\"📏 Longueur maximale: {MAX_LENGTH}\")\n",
    "print(f\"🎯 Nombre de classes: {len(all_intents)}\")\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"✅ Tokenizer chargé: {len(tokenizer)} tokens dans le vocabulaire\")\n",
    "\n",
    "# Division train/validation/test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['intent'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['intent'])\n",
    "\n",
    "print(f\"📊 Répartition des données:\")\n",
    "print(f\"  - Train: {len(train_df)} échantillons ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Validation: {len(val_df)} échantillons ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Test: {len(test_df)} échantillons ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Fonction de préprocessing pour la tokenisation.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Conversion en datasets Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']].reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label']].reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']].reset_index(drop=True))\n",
    "\n",
    "# Tokenisation\n",
    "print(\"🔄 Tokenisation en cours...\")\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Configuration des colonnes\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"✅ Tokenisation terminée\")\n",
    "print(f\"📝 Exemple tokenisé:\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"  Label: {sample['label']} ({id_to_intent[sample['label'].item()]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba625f",
   "metadata": {},
   "source": [
    "## 🧠 Configuration et Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd121720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(all_intents),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "print(f\"🤖 Modèle chargé: {sum(p.numel() for p in model.parameters()):,} paramètres\")\n",
    "print(f\"🎯 Nombre de classes de sortie: {model.num_labels}\")\n",
    "\n",
    "# Configuration de l'entraînement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../models/intent_classifier',\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir='../logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=None,  # Désactiver wandb pour ce notebook\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"⚙️ Configuration d'entraînement:\")\n",
    "print(f\"  - Épochs: {NUM_EPOCHS}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"  - Weight decay: {training_args.weight_decay}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques d'évaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calcule les métriques d'évaluation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calcul des métriques\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Configuration du trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"✅ Trainer configuré avec early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "print(\"🚀 Début de l'entraînement...\")\n",
    "print(f\"⏱️ Temps estimé: ~{NUM_EPOCHS * len(train_dataset) // BATCH_SIZE // 60} minutes\")\n",
    "\n",
    "# Démarrage de l'entraînement\n",
    "trainer.train()\n",
    "\n",
    "print(\"🎉 Entraînement terminé !\")\n",
    "\n",
    "# Sauvegarde du meilleur modèle\n",
    "trainer.save_model('../models/intent_classifier_best')\n",
    "tokenizer.save_pretrained('../models/intent_classifier_best')\n",
    "\n",
    "print(\"💾 Modèle sauvegardé dans ../models/intent_classifier_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c26b4",
   "metadata": {},
   "source": [
    "## 📈 Évaluation et Métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f333ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation sur l'ensemble de test\n",
    "print(\"🧪 Évaluation sur l'ensemble de test...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"📊 Résultats finaux:\")\n",
    "for metric, value in test_results.items():\n",
    "    if 'eval_' in metric:\n",
    "        clean_metric = metric.replace('eval_', '')\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {clean_metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "# Prédictions détaillées\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Confidence scores\n",
    "confidence_scores = torch.softmax(torch.tensor(predictions.predictions), dim=1)\n",
    "max_confidence = torch.max(confidence_scores, dim=1)[0].numpy()\n",
    "\n",
    "print(f\"\\n🎯 Confidence moyenne: {np.mean(max_confidence):.4f}\")\n",
    "print(f\"📊 Distribution des confidence scores:\")\n",
    "print(f\"  - > 0.9: {np.sum(max_confidence > 0.9) / len(max_confidence) * 100:.1f}%\")\n",
    "print(f\"  - 0.7-0.9: {np.sum((max_confidence > 0.7) & (max_confidence <= 0.9)) / len(max_confidence) * 100:.1f}%\")\n",
    "print(f\"  - < 0.7: {np.sum(max_confidence <= 0.7) / len(max_confidence) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification détaillé\n",
    "intent_names = [id_to_intent[i] for i in range(len(all_intents))]\n",
    "classification_rep = classification_report(\n",
    "    y_true, y_pred, \n",
    "    target_names=intent_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Conversion en DataFrame pour une meilleure visualisation\n",
    "class_df = pd.DataFrame(classification_rep).transpose()\n",
    "class_df = class_df.sort_values('f1-score', ascending=False)\n",
    "\n",
    "print(\"🏆 Top 10 des meilleures intentions (F1-score):\")\n",
    "top_10 = class_df.head(10)\n",
    "for intent, row in top_10.iterrows():\n",
    "    if intent not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        print(f\"  {intent}: F1={row['f1-score']:.3f}, Précision={row['precision']:.3f}, Rappel={row['recall']:.3f}\")\n",
    "\n",
    "print(\"\\n⚠️ Intentions les plus difficiles (F1-score):\")\n",
    "bottom_5 = class_df.tail(8).head(5)  # Éviter les moyennes\n",
    "for intent, row in bottom_5.iterrows():\n",
    "    if intent not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        print(f\"  {intent}: F1={row['f1-score']:.3f}, Précision={row['precision']:.3f}, Rappel={row['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e92f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualisation de la matrice de confusion (version simplifiée par domaine)\n",
    "domain_mapping = {}\n",
    "for intent in all_intents:\n",
    "    for domain, intents in INTENT_CATEGORIES.items():\n",
    "        if intent in intents:\n",
    "            domain_mapping[intent] = domain\n",
    "            break\n",
    "\n",
    "# Agrégation par domaine\n",
    "y_true_domain = [domain_mapping[id_to_intent[label]] for label in y_true]\n",
    "y_pred_domain = [domain_mapping[id_to_intent[pred]] for pred in y_pred]\n",
    "\n",
    "domain_cm = confusion_matrix(y_true_domain, y_pred_domain, labels=list(INTENT_CATEGORIES.keys()))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(domain_cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=list(INTENT_CATEGORIES.keys()),\n",
    "            yticklabels=list(INTENT_CATEGORIES.keys()))\n",
    "plt.title('Matrice de Confusion par Domaine')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.ylabel('Vraies étiquettes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy par domaine\n",
    "domain_accuracy = {}\n",
    "for domain in INTENT_CATEGORIES.keys():\n",
    "    domain_mask = [d == domain for d in y_true_domain]\n",
    "    if sum(domain_mask) > 0:\n",
    "        domain_true = [y_true_domain[i] for i, mask in enumerate(domain_mask) if mask]\n",
    "        domain_pred = [y_pred_domain[i] for i, mask in enumerate(domain_mask) if mask]\n",
    "        domain_accuracy[domain] = accuracy_score(domain_true, domain_pred)\n",
    "\n",
    "print(\"🎯 Accuracy par domaine:\")\n",
    "for domain, acc in sorted(domain_accuracy.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {domain}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a33ab",
   "metadata": {},
   "source": [
    "## 🧪 Tests et Démonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca016a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text: str, model, tokenizer, top_k: int = 3):\n",
    "    \"\"\"Prédit l'intention d'un texte avec les top-k prédictions.\"\"\"\n",
    "    \n",
    "    # Tokenisation\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    # Prédiction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    \n",
    "    # Top-k prédictions\n",
    "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        intent_id = top_k_indices[0][i].item()\n",
    "        intent_name = id_to_intent[intent_id]\n",
    "        confidence = top_k_probs[0][i].item()\n",
    "        domain = domain_mapping[intent_name]\n",
    "        \n",
    "        results.append({\n",
    "            'intent': intent_name,\n",
    "            'domain': domain,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Tests avec des exemples\n",
    "test_examples = [\n",
    "    \"Mon code Python ne marche pas, peux-tu m'aider ?\",\n",
    "    \"Je cherche un téléphone pas cher\",\n",
    "    \"Bonjour, comment ça va ?\",\n",
    "    \"Quels sont les postes disponibles dans votre entreprise ?\",\n",
    "    \"Can you translate this text to French?\",\n",
    "    \"I need help with debugging my JavaScript\",\n",
    "    \"What's the price of this laptop?\",\n",
    "    \"Merci beaucoup pour votre aide\",\n",
    "    \"How do I prepare for a technical interview?\",\n",
    "    \"¿Puedes ayudarme con la gramática española?\"\n",
    "]\n",
    "\n",
    "print(\"🧪 Tests de prédiction d'intentions:\\n\")\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    print(f\"📝 Test {i}: '{text}'\")\n",
    "    predictions = predict_intent(text, model, tokenizer, top_k=3)\n",
    "    \n",
    "    print(\"🎯 Prédictions:\")\n",
    "    for j, pred in enumerate(predictions, 1):\n",
    "        print(f\"  {j}. {pred['intent']} ({pred['domain']}) - {pred['confidence']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1dd79",
   "metadata": {},
   "source": [
    "## 📈 Analyse des Erreurs et Améliorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des erreurs les plus fréquentes\n",
    "error_analysis = []\n",
    "\n",
    "for i, (true_label, pred_label, confidence) in enumerate(zip(y_true, y_pred, max_confidence)):\n",
    "    if true_label != pred_label:\n",
    "        error_analysis.append({\n",
    "            'text': test_df.iloc[i]['text'],\n",
    "            'true_intent': id_to_intent[true_label],\n",
    "            'pred_intent': id_to_intent[pred_label],\n",
    "            'true_domain': domain_mapping[id_to_intent[true_label]],\n",
    "            'pred_domain': domain_mapping[id_to_intent[pred_label]],\n",
    "            'confidence': confidence,\n",
    "            'cross_domain': domain_mapping[id_to_intent[true_label]] != domain_mapping[id_to_intent[pred_label]]\n",
    "        })\n",
    "\n",
    "error_df = pd.DataFrame(error_analysis)\n",
    "\n",
    "print(f\"❌ Nombre total d'erreurs: {len(error_df)} sur {len(y_true)} ({len(error_df)/len(y_true)*100:.1f}%)\")\n",
    "\n",
    "if len(error_df) > 0:\n",
    "    print(f\"🔄 Erreurs inter-domaines: {error_df['cross_domain'].sum()} ({error_df['cross_domain'].sum()/len(error_df)*100:.1f}%)\")\n",
    "    print(f\"📊 Confidence moyenne des erreurs: {error_df['confidence'].mean():.3f}\")\n",
    "    \n",
    "    print(\"\\n🔍 Erreurs les plus fréquentes:\")\n",
    "    error_patterns = error_df.groupby(['true_intent', 'pred_intent']).size().sort_values(ascending=False).head(10)\n",
    "    for (true_intent, pred_intent), count in error_patterns.items():\n",
    "        print(f\"  {true_intent} → {pred_intent}: {count} fois\")\n",
    "    \n",
    "    print(\"\\n⚠️ Exemples d'erreurs avec faible confidence:\")\n",
    "    low_confidence_errors = error_df[error_df['confidence'] < 0.7].head(5)\n",
    "    for _, row in low_confidence_errors.iterrows():\n",
    "        print(f\"  '{row['text']}'\")\n",
    "        print(f\"    Vraie: {row['true_intent']} | Prédite: {row['pred_intent']} | Conf: {row['confidence']:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb50d52",
   "metadata": {},
   "source": [
    "## 💾 Sauvegarde et Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602eef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des métadonnées du modèle\n",
    "model_metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'num_labels': len(all_intents),\n",
    "    'intent_to_id': intent_to_id,\n",
    "    'id_to_intent': id_to_intent,\n",
    "    'intent_categories': INTENT_CATEGORIES,\n",
    "    'domain_mapping': domain_mapping,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'training_params': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'max_length': MAX_LENGTH\n",
    "    },\n",
    "    'performance': {\n",
    "        'test_accuracy': test_results['eval_accuracy'],\n",
    "        'test_f1': test_results['eval_f1'],\n",
    "        'test_precision': test_results['eval_precision'],\n",
    "        'test_recall': test_results['eval_recall']\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df),\n",
    "        'train_samples': len(train_df),\n",
    "        'val_samples': len(val_df),\n",
    "        'test_samples': len(test_df)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarde des métadonnées\n",
    "os.makedirs('../models/intent_classifier_best', exist_ok=True)\n",
    "with open('../models/intent_classifier_best/model_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Sauvegarde des résultats détaillés\n",
    "results_summary = {\n",
    "    'classification_report': classification_rep,\n",
    "    'domain_accuracy': domain_accuracy,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'error_analysis': error_df.to_dict('records') if len(error_df) > 0 else []\n",
    "}\n",
    "\n",
    "with open('../models/intent_classifier_best/evaluation_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"💾 Métadonnées et résultats sauvegardés dans ../models/intent_classifier_best/\")\n",
    "print(\"✅ Modèle prêt pour la production !\")\n",
    "\n",
    "# Résumé final\n",
    "print(\"\\n🎉 RÉSUMÉ FINAL:\")\n",
    "print(f\"📊 Accuracy finale: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"🎯 F1-score: {test_results['eval_f1']:.4f}\")\n",
    "print(f\"🏷️ Intentions supportées: {len(all_intents)}\")\n",
    "print(f\"🌍 Domaines: {len(INTENT_CATEGORIES)}\")\n",
    "print(f\"💻 Modèle: {MODEL_NAME}\")\n",
    "print(f\"📁 Emplacement: ../models/intent_classifier_best/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
