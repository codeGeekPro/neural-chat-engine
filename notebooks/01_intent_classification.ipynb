{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf43d12b",
   "metadata": {},
   "source": [
    "# ğŸ¯ Classification d'Intentions - Neural Chat Engine\n",
    "\n",
    "## Objectif\n",
    "DÃ©velopper un modÃ¨le de classification d'intentions multi-domaines utilisant DistilBERT pour notre chatbot IA avancÃ©.\n",
    "\n",
    "## Domaines couverts\n",
    "- ğŸ”§ **Assistance technique** (documentation, debugging)\n",
    "- ğŸ›ï¸ **E-commerce** (recommandations, support client)\n",
    "- ğŸ‘¥ **RH** (screening, questions d'emploi)\n",
    "- ğŸŒ **Multilingue** (traduction contextuelle)\n",
    "\n",
    "## Architecture\n",
    "- **ModÃ¨le base** : DistilBERT (distilbert-base-multilingual-cased)\n",
    "- **Classification** : Multi-labels avec confidence scoring\n",
    "- **Optimisation** : Fine-tuning avec techniques avancÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4543582",
   "metadata": {},
   "source": [
    "## ğŸ“š Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b317bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dÃ©pendances (si nÃ©cessaire)\n",
    "# !pip install transformers torch datasets scikit-learn matplotlib seaborn wandb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ajout du path du projet\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Imports essentiels\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Transformers & ML\n",
    "from transformers import (\n",
    "    DistilBertTokenizer, \n",
    "    DistilBertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configuration du device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸš€ Device utilisÃ©: {device}\")\n",
    "print(f\"ğŸ”¢ PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Configuration pour la reproductibilitÃ©\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Style des graphiques\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251dbef6",
   "metadata": {},
   "source": [
    "## ğŸ—‚ï¸ Chargement et Exploration des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©finition des intentions par domaine\n",
    "INTENT_CATEGORIES = {\n",
    "    'technical': [\n",
    "        'code_debug', 'documentation_request', 'api_usage', \n",
    "        'error_explanation', 'best_practices', 'architecture_advice'\n",
    "    ],\n",
    "    'ecommerce': [\n",
    "        'product_search', 'price_inquiry', 'recommendation_request',\n",
    "        'order_status', 'return_policy', 'payment_help'\n",
    "    ],\n",
    "    'hr': [\n",
    "        'job_inquiry', 'interview_preparation', 'salary_negotiation',\n",
    "        'career_advice', 'skill_assessment', 'company_culture'\n",
    "    ],\n",
    "    'multilingual': [\n",
    "        'translation_request', 'language_learning', 'cultural_context',\n",
    "        'grammar_check', 'pronunciation_help', 'localization'\n",
    "    ],\n",
    "    'general': [\n",
    "        'greeting', 'goodbye', 'thank_you', 'apology', \n",
    "        'clarification_request', 'escalation_request'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# CrÃ©ation du mapping des labels\n",
    "all_intents = []\n",
    "for domain, intents in INTENT_CATEGORIES.items():\n",
    "    all_intents.extend(intents)\n",
    "\n",
    "intent_to_id = {intent: i for i, intent in enumerate(all_intents)}\n",
    "id_to_intent = {i: intent for intent, i in intent_to_id.items()}\n",
    "\n",
    "print(f\"ğŸ“Š Nombre total d'intentions: {len(all_intents)}\")\n",
    "print(f\"ğŸ·ï¸ Intentions par domaine:\")\n",
    "for domain, intents in INTENT_CATEGORIES.items():\n",
    "    print(f\"  - {domain}: {len(intents)} intentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ceb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GÃ©nÃ©ration de donnÃ©es d'exemple (en attendant les vraies donnÃ©es)\n",
    "def generate_sample_data(num_samples_per_intent: int = 50) -> List[Dict]:\n",
    "    \"\"\"GÃ©nÃ¨re des donnÃ©es d'exemple pour chaque intention.\"\"\"\n",
    "    \n",
    "    sample_texts = {\n",
    "        # Technical\n",
    "        'code_debug': [\n",
    "            \"Mon code Python ne fonctionne pas, pouvez-vous m'aider ?\",\n",
    "            \"J'ai une erreur dans ma fonction, comment la corriger ?\",\n",
    "            \"Help me debug this JavaScript issue\",\n",
    "            \"There's a bug in my React component\"\n",
    "        ],\n",
    "        'documentation_request': [\n",
    "            \"OÃ¹ puis-je trouver la documentation de cette API ?\",\n",
    "            \"Can you show me the docs for this library?\",\n",
    "            \"I need help understanding this framework\",\n",
    "            \"Comment utiliser cette bibliothÃ¨que ?\"\n",
    "        ],\n",
    "        # E-commerce\n",
    "        'product_search': [\n",
    "            \"Je cherche un ordinateur portable pour le gaming\",\n",
    "            \"Show me smartphones under $500\",\n",
    "            \"Quels sont vos meilleurs tÃ©lÃ©phones ?\",\n",
    "            \"I'm looking for wireless headphones\"\n",
    "        ],\n",
    "        'price_inquiry': [\n",
    "            \"Quel est le prix de ce produit ?\",\n",
    "            \"How much does this cost?\",\n",
    "            \"Is there a discount available?\",\n",
    "            \"Y a-t-il des promotions en cours ?\"\n",
    "        ],\n",
    "        # HR\n",
    "        'job_inquiry': [\n",
    "            \"Quels postes sont disponibles ?\",\n",
    "            \"Are there any developer positions open?\",\n",
    "            \"I'm interested in working at your company\",\n",
    "            \"Comment postuler pour un emploi ?\"\n",
    "        ],\n",
    "        'interview_preparation': [\n",
    "            \"Comment me prÃ©parer pour l'entretien ?\",\n",
    "            \"What questions should I expect?\",\n",
    "            \"Tips for a technical interview?\",\n",
    "            \"Conseils pour rÃ©ussir l'entretien\"\n",
    "        ],\n",
    "        # Multilingual\n",
    "        'translation_request': [\n",
    "            \"Pouvez-vous traduire ce texte en anglais ?\",\n",
    "            \"Translate this to French please\",\n",
    "            \"Â¿Puedes traducir esto al espaÃ±ol?\",\n",
    "            \"ã“ã®æ–‡ã‚’è‹±èªã«ç¿»è¨³ã—ã¦ãã ã•ã„\"\n",
    "        ],\n",
    "        # General\n",
    "        'greeting': [\n",
    "            \"Bonjour !\", \"Hello!\", \"Hi there\", \"Salut\",\n",
    "            \"Good morning\", \"Bonsoir\", \"Hey\", \"Hola\"\n",
    "        ],\n",
    "        'thank_you': [\n",
    "            \"Merci beaucoup\", \"Thank you\", \"Thanks a lot\",\n",
    "            \"Je vous remercie\", \"Much appreciated\", \"Gracias\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for intent in all_intents:\n",
    "        if intent in sample_texts:\n",
    "            base_samples = sample_texts[intent]\n",
    "        else:\n",
    "            # GÃ©nÃ©ration de textes gÃ©nÃ©riques pour les intentions non dÃ©finies\n",
    "            base_samples = [\n",
    "                f\"This is about {intent.replace('_', ' ')}\",\n",
    "                f\"I need help with {intent.replace('_', ' ')}\",\n",
    "                f\"Question about {intent.replace('_', ' ')}\",\n",
    "                f\"How to handle {intent.replace('_', ' ')}?\"\n",
    "            ]\n",
    "        \n",
    "        # Augmentation des donnÃ©es\n",
    "        for i in range(num_samples_per_intent):\n",
    "            text = np.random.choice(base_samples)\n",
    "            # Ajout de variations\n",
    "            if np.random.random() > 0.7:\n",
    "                prefixes = [\"Could you help me with \", \"I have a question about \", \"\"]\n",
    "                text = np.random.choice(prefixes) + text.lower()\n",
    "            \n",
    "            data.append({\n",
    "                'text': text,\n",
    "                'intent': intent,\n",
    "                'label': intent_to_id[intent],\n",
    "                'domain': next(domain for domain, intents in INTENT_CATEGORIES.items() if intent in intents)\n",
    "            })\n",
    "    \n",
    "    return data\n",
    "\n",
    "# GÃ©nÃ©ration des donnÃ©es\n",
    "print(\"ğŸ”„ GÃ©nÃ©ration des donnÃ©es d'exemple...\")\n",
    "raw_data = generate_sample_data(num_samples_per_intent=75)\n",
    "df = pd.DataFrame(raw_data)\n",
    "\n",
    "print(f\"ğŸ“ˆ Dataset crÃ©Ã©: {len(df)} Ã©chantillons\")\n",
    "print(f\"ğŸ“Š RÃ©partition par domaine:\")\n",
    "print(df['domain'].value_counts())\n",
    "\n",
    "# Affichage d'exemples\n",
    "print(\"\\nğŸ“ Exemples de donnÃ©es:\")\n",
    "sample_data = df.groupby('domain').head(2)\n",
    "for _, row in sample_data.iterrows():\n",
    "    print(f\"  {row['domain']} | {row['intent']} | '{row['text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b96f1",
   "metadata": {},
   "source": [
    "## ğŸ“Š Analyse Exploratoire des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques gÃ©nÃ©rales\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Distribution par domaine\n",
    "df['domain'].value_counts().plot(kind='bar', ax=axes[0,0], color='skyblue')\n",
    "axes[0,0].set_title('Distribution par Domaine')\n",
    "axes[0,0].set_xlabel('Domaine')\n",
    "axes[0,0].set_ylabel('Nombre d\\'Ã©chantillons')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Longueur des textes\n",
    "df['text_length'] = df['text'].str.len()\n",
    "df['text_length'].hist(bins=30, ax=axes[0,1], color='lightcoral')\n",
    "axes[0,1].set_title('Distribution de la Longueur des Textes')\n",
    "axes[0,1].set_xlabel('Longueur (caractÃ¨res)')\n",
    "axes[0,1].set_ylabel('FrÃ©quence')\n",
    "\n",
    "# Top 10 des intentions\n",
    "top_intents = df['intent'].value_counts().head(10)\n",
    "top_intents.plot(kind='barh', ax=axes[1,0], color='lightgreen')\n",
    "axes[1,0].set_title('Top 10 des Intentions')\n",
    "axes[1,0].set_xlabel('Nombre d\\'Ã©chantillons')\n",
    "\n",
    "# Nombre de mots par domaine\n",
    "df['word_count'] = df['text'].str.split().str.len()\n",
    "df.boxplot(column='word_count', by='domain', ax=axes[1,1])\n",
    "axes[1,1].set_title('Distribution du Nombre de Mots par Domaine')\n",
    "axes[1,1].set_xlabel('Domaine')\n",
    "axes[1,1].set_ylabel('Nombre de mots')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques descriptives\n",
    "print(\"ğŸ“ˆ Statistiques descriptives:\")\n",
    "print(f\"Longueur moyenne des textes: {df['text_length'].mean():.1f} caractÃ¨res\")\n",
    "print(f\"Nombre moyen de mots: {df['word_count'].mean():.1f}\")\n",
    "print(f\"Ã‰chantillons les plus courts: {df['text_length'].min()} caractÃ¨res\")\n",
    "print(f\"Ã‰chantillons les plus longs: {df['text_length'].max()} caractÃ¨res\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75ce57",
   "metadata": {},
   "source": [
    "## ğŸ”§ PrÃ©paration des DonnÃ©es et Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ec4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du modÃ¨le\n",
    "MODEL_NAME = \"distilbert-base-multilingual-cased\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "print(f\"ğŸ¤– ModÃ¨le: {MODEL_NAME}\")\n",
    "print(f\"ğŸ“ Longueur maximale: {MAX_LENGTH}\")\n",
    "print(f\"ğŸ¯ Nombre de classes: {len(all_intents)}\")\n",
    "\n",
    "# Chargement du tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"âœ… Tokenizer chargÃ©: {len(tokenizer)} tokens dans le vocabulaire\")\n",
    "\n",
    "# Division train/validation/test\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42, stratify=df['intent'])\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['intent'])\n",
    "\n",
    "print(f\"ğŸ“Š RÃ©partition des donnÃ©es:\")\n",
    "print(f\"  - Train: {len(train_df)} Ã©chantillons ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Validation: {len(val_df)} Ã©chantillons ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Test: {len(test_df)} Ã©chantillons ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    \"\"\"Fonction de prÃ©processing pour la tokenisation.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "# Conversion en datasets Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']].reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label']].reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']].reset_index(drop=True))\n",
    "\n",
    "# Tokenisation\n",
    "print(\"ğŸ”„ Tokenisation en cours...\")\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Configuration des colonnes\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"âœ… Tokenisation terminÃ©e\")\n",
    "print(f\"ğŸ“ Exemple tokenisÃ©:\")\n",
    "sample = train_dataset[0]\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"  Label: {sample['label']} ({id_to_intent[sample['label'].item()]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eba625f",
   "metadata": {},
   "source": [
    "## ğŸ§  Configuration et EntraÃ®nement du ModÃ¨le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd121720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modÃ¨le\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(all_intents),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸ¤– ModÃ¨le chargÃ©: {sum(p.numel() for p in model.parameters()):,} paramÃ¨tres\")\n",
    "print(f\"ğŸ¯ Nombre de classes de sortie: {model.num_labels}\")\n",
    "\n",
    "# Configuration de l'entraÃ®nement\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='../models/intent_classifier',\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir='../logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=None,  # DÃ©sactiver wandb pour ce notebook\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"âš™ï¸ Configuration d'entraÃ®nement:\")\n",
    "print(f\"  - Ã‰pochs: {NUM_EPOCHS}\")\n",
    "print(f\"  - Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  - Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  - Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"  - Weight decay: {training_args.weight_decay}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf6449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÃ©triques d'Ã©valuation\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calcule les mÃ©triques d'Ã©valuation.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Calcul des mÃ©triques\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Configuration du trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"âœ… Trainer configurÃ© avec early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EntraÃ®nement du modÃ¨le\n",
    "print(\"ğŸš€ DÃ©but de l'entraÃ®nement...\")\n",
    "print(f\"â±ï¸ Temps estimÃ©: ~{NUM_EPOCHS * len(train_dataset) // BATCH_SIZE // 60} minutes\")\n",
    "\n",
    "# DÃ©marrage de l'entraÃ®nement\n",
    "trainer.train()\n",
    "\n",
    "print(\"ğŸ‰ EntraÃ®nement terminÃ© !\")\n",
    "\n",
    "# Sauvegarde du meilleur modÃ¨le\n",
    "trainer.save_model('../models/intent_classifier_best')\n",
    "tokenizer.save_pretrained('../models/intent_classifier_best')\n",
    "\n",
    "print(\"ğŸ’¾ ModÃ¨le sauvegardÃ© dans ../models/intent_classifier_best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c26b4",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Ã‰valuation et MÃ©triques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f333ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã‰valuation sur l'ensemble de test\n",
    "print(\"ğŸ§ª Ã‰valuation sur l'ensemble de test...\")\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"ğŸ“Š RÃ©sultats finaux:\")\n",
    "for metric, value in test_results.items():\n",
    "    if 'eval_' in metric:\n",
    "        clean_metric = metric.replace('eval_', '')\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {clean_metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "# PrÃ©dictions dÃ©taillÃ©es\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Confidence scores\n",
    "confidence_scores = torch.softmax(torch.tensor(predictions.predictions), dim=1)\n",
    "max_confidence = torch.max(confidence_scores, dim=1)[0].numpy()\n",
    "\n",
    "print(f\"\\nğŸ¯ Confidence moyenne: {np.mean(max_confidence):.4f}\")\n",
    "print(f\"ğŸ“Š Distribution des confidence scores:\")\n",
    "print(f\"  - > 0.9: {np.sum(max_confidence > 0.9) / len(max_confidence) * 100:.1f}%\")\n",
    "print(f\"  - 0.7-0.9: {np.sum((max_confidence > 0.7) & (max_confidence <= 0.9)) / len(max_confidence) * 100:.1f}%\")\n",
    "print(f\"  - < 0.7: {np.sum(max_confidence <= 0.7) / len(max_confidence) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rapport de classification dÃ©taillÃ©\n",
    "intent_names = [id_to_intent[i] for i in range(len(all_intents))]\n",
    "classification_rep = classification_report(\n",
    "    y_true, y_pred, \n",
    "    target_names=intent_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Conversion en DataFrame pour une meilleure visualisation\n",
    "class_df = pd.DataFrame(classification_rep).transpose()\n",
    "class_df = class_df.sort_values('f1-score', ascending=False)\n",
    "\n",
    "print(\"ğŸ† Top 10 des meilleures intentions (F1-score):\")\n",
    "top_10 = class_df.head(10)\n",
    "for intent, row in top_10.iterrows():\n",
    "    if intent not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        print(f\"  {intent}: F1={row['f1-score']:.3f}, PrÃ©cision={row['precision']:.3f}, Rappel={row['recall']:.3f}\")\n",
    "\n",
    "print(\"\\nâš ï¸ Intentions les plus difficiles (F1-score):\")\n",
    "bottom_5 = class_df.tail(8).head(5)  # Ã‰viter les moyennes\n",
    "for intent, row in bottom_5.iterrows():\n",
    "    if intent not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "        print(f\"  {intent}: F1={row['f1-score']:.3f}, PrÃ©cision={row['precision']:.3f}, Rappel={row['recall']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e92f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualisation de la matrice de confusion (version simplifiÃ©e par domaine)\n",
    "domain_mapping = {}\n",
    "for intent in all_intents:\n",
    "    for domain, intents in INTENT_CATEGORIES.items():\n",
    "        if intent in intents:\n",
    "            domain_mapping[intent] = domain\n",
    "            break\n",
    "\n",
    "# AgrÃ©gation par domaine\n",
    "y_true_domain = [domain_mapping[id_to_intent[label]] for label in y_true]\n",
    "y_pred_domain = [domain_mapping[id_to_intent[pred]] for pred in y_pred]\n",
    "\n",
    "domain_cm = confusion_matrix(y_true_domain, y_pred_domain, labels=list(INTENT_CATEGORIES.keys()))\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(domain_cm, \n",
    "            annot=True, \n",
    "            fmt='d', \n",
    "            cmap='Blues',\n",
    "            xticklabels=list(INTENT_CATEGORIES.keys()),\n",
    "            yticklabels=list(INTENT_CATEGORIES.keys()))\n",
    "plt.title('Matrice de Confusion par Domaine')\n",
    "plt.xlabel('PrÃ©dictions')\n",
    "plt.ylabel('Vraies Ã©tiquettes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Accuracy par domaine\n",
    "domain_accuracy = {}\n",
    "for domain in INTENT_CATEGORIES.keys():\n",
    "    domain_mask = [d == domain for d in y_true_domain]\n",
    "    if sum(domain_mask) > 0:\n",
    "        domain_true = [y_true_domain[i] for i, mask in enumerate(domain_mask) if mask]\n",
    "        domain_pred = [y_pred_domain[i] for i, mask in enumerate(domain_mask) if mask]\n",
    "        domain_accuracy[domain] = accuracy_score(domain_true, domain_pred)\n",
    "\n",
    "print(\"ğŸ¯ Accuracy par domaine:\")\n",
    "for domain, acc in sorted(domain_accuracy.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {domain}: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a33ab",
   "metadata": {},
   "source": [
    "## ğŸ§ª Tests et DÃ©monstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca016a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_intent(text: str, model, tokenizer, top_k: int = 3):\n",
    "    \"\"\"PrÃ©dit l'intention d'un texte avec les top-k prÃ©dictions.\"\"\"\n",
    "    \n",
    "    # Tokenisation\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    # PrÃ©diction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
    "    \n",
    "    # Top-k prÃ©dictions\n",
    "    top_k_probs, top_k_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(top_k):\n",
    "        intent_id = top_k_indices[0][i].item()\n",
    "        intent_name = id_to_intent[intent_id]\n",
    "        confidence = top_k_probs[0][i].item()\n",
    "        domain = domain_mapping[intent_name]\n",
    "        \n",
    "        results.append({\n",
    "            'intent': intent_name,\n",
    "            'domain': domain,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Tests avec des exemples\n",
    "test_examples = [\n",
    "    \"Mon code Python ne marche pas, peux-tu m'aider ?\",\n",
    "    \"Je cherche un tÃ©lÃ©phone pas cher\",\n",
    "    \"Bonjour, comment Ã§a va ?\",\n",
    "    \"Quels sont les postes disponibles dans votre entreprise ?\",\n",
    "    \"Can you translate this text to French?\",\n",
    "    \"I need help with debugging my JavaScript\",\n",
    "    \"What's the price of this laptop?\",\n",
    "    \"Merci beaucoup pour votre aide\",\n",
    "    \"How do I prepare for a technical interview?\",\n",
    "    \"Â¿Puedes ayudarme con la gramÃ¡tica espaÃ±ola?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Tests de prÃ©diction d'intentions:\\n\")\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    print(f\"ğŸ“ Test {i}: '{text}'\")\n",
    "    predictions = predict_intent(text, model, tokenizer, top_k=3)\n",
    "    \n",
    "    print(\"ğŸ¯ PrÃ©dictions:\")\n",
    "    for j, pred in enumerate(predictions, 1):\n",
    "        print(f\"  {j}. {pred['intent']} ({pred['domain']}) - {pred['confidence']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1dd79",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Analyse des Erreurs et AmÃ©liorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des erreurs les plus frÃ©quentes\n",
    "error_analysis = []\n",
    "\n",
    "for i, (true_label, pred_label, confidence) in enumerate(zip(y_true, y_pred, max_confidence)):\n",
    "    if true_label != pred_label:\n",
    "        error_analysis.append({\n",
    "            'text': test_df.iloc[i]['text'],\n",
    "            'true_intent': id_to_intent[true_label],\n",
    "            'pred_intent': id_to_intent[pred_label],\n",
    "            'true_domain': domain_mapping[id_to_intent[true_label]],\n",
    "            'pred_domain': domain_mapping[id_to_intent[pred_label]],\n",
    "            'confidence': confidence,\n",
    "            'cross_domain': domain_mapping[id_to_intent[true_label]] != domain_mapping[id_to_intent[pred_label]]\n",
    "        })\n",
    "\n",
    "error_df = pd.DataFrame(error_analysis)\n",
    "\n",
    "print(f\"âŒ Nombre total d'erreurs: {len(error_df)} sur {len(y_true)} ({len(error_df)/len(y_true)*100:.1f}%)\")\n",
    "\n",
    "if len(error_df) > 0:\n",
    "    print(f\"ğŸ”„ Erreurs inter-domaines: {error_df['cross_domain'].sum()} ({error_df['cross_domain'].sum()/len(error_df)*100:.1f}%)\")\n",
    "    print(f\"ğŸ“Š Confidence moyenne des erreurs: {error_df['confidence'].mean():.3f}\")\n",
    "    \n",
    "    print(\"\\nğŸ” Erreurs les plus frÃ©quentes:\")\n",
    "    error_patterns = error_df.groupby(['true_intent', 'pred_intent']).size().sort_values(ascending=False).head(10)\n",
    "    for (true_intent, pred_intent), count in error_patterns.items():\n",
    "        print(f\"  {true_intent} â†’ {pred_intent}: {count} fois\")\n",
    "    \n",
    "    print(\"\\nâš ï¸ Exemples d'erreurs avec faible confidence:\")\n",
    "    low_confidence_errors = error_df[error_df['confidence'] < 0.7].head(5)\n",
    "    for _, row in low_confidence_errors.iterrows():\n",
    "        print(f\"  '{row['text']}'\")\n",
    "        print(f\"    Vraie: {row['true_intent']} | PrÃ©dite: {row['pred_intent']} | Conf: {row['confidence']:.3f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb50d52",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Sauvegarde et Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602eef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des mÃ©tadonnÃ©es du modÃ¨le\n",
    "model_metadata = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'num_labels': len(all_intents),\n",
    "    'intent_to_id': intent_to_id,\n",
    "    'id_to_intent': id_to_intent,\n",
    "    'intent_categories': INTENT_CATEGORIES,\n",
    "    'domain_mapping': domain_mapping,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'training_params': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS,\n",
    "        'max_length': MAX_LENGTH\n",
    "    },\n",
    "    'performance': {\n",
    "        'test_accuracy': test_results['eval_accuracy'],\n",
    "        'test_f1': test_results['eval_f1'],\n",
    "        'test_precision': test_results['eval_precision'],\n",
    "        'test_recall': test_results['eval_recall']\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df),\n",
    "        'train_samples': len(train_df),\n",
    "        'val_samples': len(val_df),\n",
    "        'test_samples': len(test_df)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarde des mÃ©tadonnÃ©es\n",
    "os.makedirs('../models/intent_classifier_best', exist_ok=True)\n",
    "with open('../models/intent_classifier_best/model_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(model_metadata, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Sauvegarde des rÃ©sultats dÃ©taillÃ©s\n",
    "results_summary = {\n",
    "    'classification_report': classification_rep,\n",
    "    'domain_accuracy': domain_accuracy,\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'error_analysis': error_df.to_dict('records') if len(error_df) > 0 else []\n",
    "}\n",
    "\n",
    "with open('../models/intent_classifier_best/evaluation_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(results_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"ğŸ’¾ MÃ©tadonnÃ©es et rÃ©sultats sauvegardÃ©s dans ../models/intent_classifier_best/\")\n",
    "print(\"âœ… ModÃ¨le prÃªt pour la production !\")\n",
    "\n",
    "# RÃ©sumÃ© final\n",
    "print(\"\\nğŸ‰ RÃ‰SUMÃ‰ FINAL:\")\n",
    "print(f\"ğŸ“Š Accuracy finale: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"ğŸ¯ F1-score: {test_results['eval_f1']:.4f}\")\n",
    "print(f\"ğŸ·ï¸ Intentions supportÃ©es: {len(all_intents)}\")\n",
    "print(f\"ğŸŒ Domaines: {len(INTENT_CATEGORIES)}\")\n",
    "print(f\"ğŸ’» ModÃ¨le: {MODEL_NAME}\")\n",
    "print(f\"ğŸ“ Emplacement: ../models/intent_classifier_best/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
